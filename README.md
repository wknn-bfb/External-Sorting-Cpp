# External Sorting(外部排序)实践

本项目包含两个循序渐进的外部排序（External Sorting）实现，旨在解决在大数据量（远超内存容量）场景下，如何高效地进行数据排序的问题。项目从基础的二路归并演进到利用败者树、并行I/O和最佳归并的高性能排序系统。

## 项目简介

### 1. 实验背景

在实际的大数据处理场景中，待排序的数据量往往远大于计算机的内存容量（例如，对 GB 级、甚至 TB 级的数据进行排序，而内存仅为 MB 级）。这种情况下，直接将所有数据加载到内存进行内部排序是不可行的。因此，需要采用外部排序技术，利用磁盘作为辅助存储，通过分批处理和归并来完成排序。

### 2. 项目解决的问题

- **Project 1 (基础版)**：解决了大数据量无法一次性读入内存的问题。实现了基础的“分块内排 + 迭代二路归并”策略，利用有限的内存缓冲区（Buffer）作为磁盘与 CPU 之间的桥梁。
- **Project 2 (进阶版)**：解决了 Project 1 中“归并段长度受限”和“I/O 串行阻塞”的瓶颈。引入了败者树（置换-选择排序）和双缓冲并行技术，显著减少了初始归并段的数量并提高了 I/O 效率。

## 项目文件结构及系统架构

### 1. 文件结构
```text
Root
├── project1/           # [基础版]：内排 + 迭代式二路归并
│   ├── main.cpp
│   ├── RunFile.h
│   ├── InputBuffer.h
│   ├── OutputBuffer.h
│   ├── RunGenerator.h
│   └── Merger.h
│
├── project2/           # [进阶版]：置换选择排序 + 并行生成 + 最佳归并树
│   ├── main.cpp
│   ├── RunFile.h
│   ├── InputBuffer.h
│   ├── OutputBuffer.h
│   ├── LoserTree.h
│   ├── RunGenerator.h
│   └── Merger.h
│
└── README.md

### 2. 系统架构

- #### Project 1 架构：基础 Sort-Merge

  - **Run Generation (生成阶段)**：采用“分块读取 -> 内存内 std::sort -> 写入磁盘”的策略。生成 N 个长度等于内存大小的初始归并段。
  - **Run Merging (归并阶段)**：基于队列的迭代式二路归并。利用 InputBuffer 和 OutputBuffer 进行 4KB 块读写，减少系统调用。

  #### Project 2 架构：并行优化

  - **败者树 (Loser Tree)**：替代内存数组排序。利用置换-选择排序原理，生成平均长度为内存大小 2 倍的归并段。
  - **生产者-消费者模型**：设计了 Input、Compute、Output 三个并发线程，配合双缓冲机制，掩盖磁盘 I/O 延迟。
  - **最佳归并树 (Optimal Merge Tree)**：利用最小堆动态选择当前长度最小的两个 Run 进行合并，最小化总 I/O 传输量。

## 测试结果与分析

### 1. 测试场景

- **数据类型**：int (4字节)。
- **数据量**：10M 个整数 (即 40MB)。
- **内存限制**：1M 个整数 (即 4MB)。
- **I/O 缓冲区**：1024 个整数 (即 4KB)。
- **数据生成**：随机生成 10M 个整数并写入二进制文件。

### 2. 测试结果与分析

- **Project 1**：

  生成了 10 个长度为 1M 的归并段。归并阶段进行了多趟迭代，I/O 开销较大。

- **Project 2**：

  利用败者树生成了 6 个不等长的归并段（大幅少于 P1），平均长度接近 2M（内存的 2 倍)。最佳归并策略显著减少了归并时间。

## 实验总结

通过这两个项目的开发，深入理解了：

1. **I/O 瓶颈**：在大数据处理中，磁盘 I/O 是最大的性能瓶颈，利用缓冲区进行块操作是基础，而利用异步 I/O 掩盖延迟是进阶。
2. **算法与硬件结合**：置换选择排序巧妙利用内存特性，打破了物理内存大小对 Run 长度的限制。
3. **并发系统设计**：在 Project 2 中设计并发模型，深刻体会了线程同步和资源竞争的处理。
